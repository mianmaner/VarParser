# VarParser: Unleashing the Neglected Power of Variables for LLM-based Log Parsing

This repository contains the official implementation of our WWW 2026 paper:

**"VarParser: Unleashing the Neglected Power of Variables for LLM-based Log Parsing".** 

*Proceedings of the ACM Web Conference (WWW), 2026*

## Clone the Repository

```bash
git clone https://github.com/mianmaner/VarParser.git
cd VarParser
```

## Repository Structure

```txt
ðŸ“¦ VarParser
â”œâ”€ dataset/
â”‚  â””â”€ 2k_dataset/            # LogHub-2k datasets
â”‚  â””â”€ full_dataset/          # LogHub-2.0 datasets
â”œâ”€ sample/                   # Sampled candidate logs
â”œâ”€ parsed/                   # Parsed log results
â”œâ”€ result/                   # Evaluation outputs
â”œâ”€ varparser/                # Core implementation
â”‚  â”œâ”€ cache.py               # Variable-aware template cache
â”‚  â”œâ”€ prompt.py              # LLM prompt construction & querying
â”‚  â”œâ”€ utils.py               # Log preprocessing utilities
â”‚  â””â”€ eval.py                # Parsing evaluation
â”œâ”€ running.py                # Main entry for online log parsing
â”œâ”€ sample.py                 # Candidate sampling script
â”œâ”€ config.yaml               # LLM configuration
â”œâ”€ requirements.txt
â””â”€ README.md
```

## Prerequisites

Ensure you have Python 3.11+ installed.
```txt
pip install -r requirements.txt
```

Then set your OpenAI API information in `config.yaml`.

```txt
model: "<MODEL_NAME>"
api_key: "<OpenAI_API_KEY>"
base_url: "<OpenAI_BASE_URL>"
```

## Minimal Running Example
You can excute the following command to quickly run VarParser:

```bash
bash run_parser.sh Thunderbird 2k
```

This command performs online log parsing on the Thunderbird dataset using the 2k log subset.

By default, the script will parse all datasets in LogHub-2.0 using the specified LLM configuration.

Parsed log results will be saved to:
```txt
parsed/
```

Evaluation results (e.g., parsing accuracy, runtime, token usage) will be saved to:
```txt
result/
```

## Dataset

We conduct experiments on LogHub-2.0, a large-scale and widely used log parsing benchmark.

Please download the datasets from Zenodo:
ðŸ”— https://zenodo.org/record/8275861

Unzip the files into the following directory:
```txt
dataset/full_dataset/
```

Example structure:

```txt
ðŸ“¦ VarParser
â”œâ”€Â dataset
|  â””â”€Â full_dataset
â”‚Â Â Â Â Â â”œâ”€Â Apache
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log_structured.csv
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log_structured_corrected.csv
â”‚Â Â Â Â Â â”‚Â Â â”œâ”€Â Apache_full.log_templates.csv
â”‚Â Â Â Â Â â”‚Â Â â””â”€Â Apache_full.log_templates_corrected.csv
â”‚Â Â Â Â Â â”œâ”€Â ...
```

## Reducible Worflow

Ensure that you have downloaded the LogHub-2.0 dataset. Then you can excute the following command to start online parsing with VarParser.

```bash
bash run_parser.sh all full
```

By default, the script will parse all datasets in LogHub-2.0 using the specified LLM configuration.

Parsed log results will be saved to:
```txt
parsed/
```

Evaluation results (e.g., parsing accuracy, runtime, token usage) will be saved to:
```txt
result/
```


### Candidate Sampling (Optional)

We have provided the saved sampled candidate logs for reproducing. You can also delete the file in `sample/` directory and excute `python sample.py`

```bash
python sample.py
```

This step is optional but recommended when adapting VarParser to new datasets.